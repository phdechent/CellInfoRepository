{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rdflib\n",
    "import concurrent.futures\n",
    "\n",
    "# Define a function to read and parse a single JSON-LD file into an RDFLib graph\n",
    "def read_and_parse_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "        graph = rdflib.Graph()\n",
    "        graph.parse(data=file_content, format='json-ld')\n",
    "    return graph\n",
    "\n",
    "# Define a function to load JSON-LD files into an RDFLib graph using concurrent processing\n",
    "def load_jsonld_files_to_graph(folder_path):\n",
    "    # Get all JSON-LD files in the specified folder\n",
    "    jsonld_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "\n",
    "    # Create an empty RDFLib graph\n",
    "    graph = rdflib.Graph()\n",
    "\n",
    "    # Use concurrent processing to read and parse files in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Map the read_and_parse_file function to each file path\n",
    "        results = executor.map(read_and_parse_file, jsonld_files)\n",
    "\n",
    "    # Combine all graphs into one\n",
    "    for g in results:\n",
    "        graph += g\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Define the folder containing the JSON-LD files\n",
    "folder_path = 'BatteryTypeJson'\n",
    "\n",
    "# Load JSON-LD files into the graph\n",
    "graph = load_jsonld_files_to_graph(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 34886 triples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the number of triples in the graph\n",
    "print(f\"Graph has {len(graph)} triples.\")\n",
    "\n",
    "# Optionally, serialize the graph to a file (e.g., in Turtle format)\n",
    "#output_file = 'output_graph.ttl'\n",
    "#graph.serialize(destination=output_file, format='turtle')\n",
    "#print(f\"Serialized graph to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCR18650BF is the subject of 54 publications\n",
      "INR18650 MJ1 is the subject of 20 publications\n",
      "INR21700 M50T is the subject of 11 publications\n",
      "SLPB11543140H5 is the subject of 9 publications\n",
      "AMP20M1HD-A is the subject of 6 publications\n",
      "INR21700 M50 is the subject of 6 publications\n",
      "SLPB75106100 is the subject of 6 publications\n",
      "MP176065 is the subject of 4 publications\n",
      "MP176065xtd is the subject of 4 publications\n",
      "SLPB100216216H is the subject of 4 publications\n"
     ]
    }
   ],
   "source": [
    "# Define the SPARQL query\n",
    "query = \"\"\"\n",
    "PREFIX schema: <https://schema.org/>\n",
    "\n",
    "SELECT ?name (COUNT(?subjectOf) AS ?subjectOfCount)\n",
    "WHERE {\n",
    "  ?thing schema:subjectOf ?subjectOf .\n",
    "  ?thing schema:name ?name .\n",
    "}\n",
    "GROUP BY ?name\n",
    "ORDER BY DESC(?subjectOfCount)\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "qres = graph.query(query)\n",
    "\n",
    "# Print the results\n",
    "for row in qres:\n",
    "    print(f\"{row.name} is the subject of {row.subjectOfCount} publications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of things with NMC active materials: 78\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Load the context file from the URL\n",
    "context_url = \"https://w3id.org/emmo/domain/battery/context\"\n",
    "context_data = requests.get(context_url).json()\n",
    "\n",
    "# Extract IRIs from the context file\n",
    "hasPositiveElectrode = rdflib.URIRef(context_data[\"@context\"][\"hasPositiveElectrode\"][\"@id\"])\n",
    "PositiveElectrode = rdflib.URIRef(context_data[\"@context\"][\"PositiveElectrode\"])\n",
    "hasActiveMaterial = rdflib.URIRef(context_data[\"@context\"][\"hasActiveMaterial\"][\"@id\"])\n",
    "NMC = rdflib.URIRef(context_data[\"@context\"][\"LithiumNickelManganeseCobaltOxide\"])\n",
    "LFP = rdflib.URIRef(context_data[\"@context\"][\"LithiumIronPhosphate\"])\n",
    "\n",
    "# Define the SPARQL query using the extracted IRIs\n",
    "query = f\"\"\"\n",
    "SELECT (COUNT(?thing) AS ?countInstance)\n",
    "WHERE {{\n",
    "  ?thing <{hasPositiveElectrode}> ?positiveElectrode .\n",
    "  ?positiveElectrode a <{PositiveElectrode}> ;\n",
    "                     <{hasActiveMaterial}> ?activeMaterial .\n",
    "  ?activeMaterial a <{NMC}> .\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "qres = graph.query(query)\n",
    "\n",
    "# Print the results\n",
    "for row in qres:\n",
    "    print(f\"Count of cells with NMC active materials: {row.countInstance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
